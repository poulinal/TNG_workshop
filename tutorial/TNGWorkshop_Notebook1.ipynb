{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beb6f17b",
   "metadata": {},
   "source": [
    "# Workshop 3: Exploring IllustrisTNG simulations to derive observationally comparable star formation rates and metallicities\n",
    "\n",
    "## Notebook 1: IllustrisTNG API and downloading data\n",
    "\n",
    "Created by Bryanne McDonough and Olivia Curtis\n",
    "\n",
    "In this notebook, you will be introduced to the different data types availbale for the TNG simulations, and how to use the TNG API to download the data you need. If you haven't download iapi_TNG.py here: https://github.com/bryannemcd/TNG_workshop/blob/main/iapi_TNG.py\n",
    "\n",
    "IMPORTANT: You will need to update iapi_TNG.py on your machine with the API key you requested from the TNG website. If you do not have an API key, request one here: https:/www.tng-project.org/users/register/\n",
    "\n",
    "Below, you will find several exercises to get practice working with the different data types available. There are also 'extensions,' prompts for you to explore data that is aligned with your interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd7a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import iapi_TNG as iapi\n",
    "#this package contains useful functions for downloading the neccessary data\n",
    "#make sure you have edited iapi_TNG.py to include your personal API key\n",
    "import numpy as np\n",
    "import h5py #most TNG data is downloaded as hdf5 files\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "\n",
    " \n",
    "baseUrl = 'http://www.tng-project.org/api/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87a6749",
   "metadata": {},
   "source": [
    "## General simulation data\n",
    "\n",
    "Using the TNG API, we can explore basic information about the simulations available.\n",
    "\n",
    "First, define your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55660641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/alexpoulin/Downloads/git/TNG/TNG_workshop']\n",
      "current dirc /Users/alexpoulin/Downloads/git/TNG/TNG_workshop/TNG_workshop_data/\n"
     ]
    }
   ],
   "source": [
    "####EDIT THIS FOR YOUR MACHINE#####\n",
    "#get current director\n",
    "'!pwd'\n",
    "#get current directory\n",
    "currentdirc=!pwd\n",
    "print(currentdirc)\n",
    "dirc= ' '.join(currentdirc) + '/TNG_workshop_data/'\n",
    "print(f\"current dirc {dirc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bccfc97",
   "metadata": {},
   "source": [
    "Then, define which simulation you would like to look at. The options include:\n",
    "\n",
    "1. TNG100-1 is the highest resolution simulation in the 100 Mpc simulation box\n",
    "2. TNG50-1 is the highest resolution available in a 50 Mpc box\n",
    "3. TNG300-1 is the largest volume simulation (300 Mpc)\n",
    "\n",
    "Here, Lower resolutions are available with -N replacing -1, allowing for testing resolution dependency.\n",
    "'Dark' simulations are also available that are are dark-matter only runs. Lastly, subboxes are availble that provide higher time resolution\n",
    "\n",
    "For the exercises in this worrkshop, you will need to use a baryonic simulation, we recommend TNG100-1, TNG50-1, or TNG300-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed721c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###specify which simulation you want to explore###\n",
    "sim='TNG100-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634daa7f",
   "metadata": {},
   "source": [
    "You can check all available simulations by running the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c040fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'simulations': [{'name': 'Illustris-1', 'num_snapshots': 134, 'url': 'http://www.tng-project.org/api/Illustris-1/'}, {'name': 'Illustris-1-Dark', 'num_snapshots': 136, 'url': 'http://www.tng-project.org/api/Illustris-1-Dark/'}, {'name': 'Illustris-2', 'num_snapshots': 136, 'url': 'http://www.tng-project.org/api/Illustris-2/'}, {'name': 'Illustris-2-Dark', 'num_snapshots': 136, 'url': 'http://www.tng-project.org/api/Illustris-2-Dark/'}, {'name': 'Illustris-3', 'num_snapshots': 136, 'url': 'http://www.tng-project.org/api/Illustris-3/'}, {'name': 'Illustris-3-Dark', 'num_snapshots': 136, 'url': 'http://www.tng-project.org/api/Illustris-3-Dark/'}, {'name': 'TNG100-1', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG100-1/'}, {'name': 'TNG100-1-Dark', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG100-1-Dark/'}, {'name': 'TNG100-2', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG100-2/'}, {'name': 'TNG100-2-Dark', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG100-2-Dark/'}, {'name': 'TNG100-3', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG100-3/'}, {'name': 'TNG100-3-Dark', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG100-3-Dark/'}, {'name': 'TNG300-3', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG300-3/'}, {'name': 'TNG300-2-Dark', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG300-2-Dark/'}, {'name': 'TNG300-2', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG300-2/'}, {'name': 'TNG300-1-Dark', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG300-1-Dark/'}, {'name': 'TNG300-1', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG300-1/'}, {'name': 'TNG300-3-Dark', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG300-3-Dark/'}, {'name': 'TNG50-1', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG50-1/'}, {'name': 'TNG50-1-Dark', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG50-1-Dark/'}, {'name': 'TNG50-2', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG50-2/'}, {'name': 'TNG50-2-Dark', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG50-2-Dark/'}, {'name': 'TNG50-3', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG50-3/'}, {'name': 'TNG50-3-Dark', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG50-3-Dark/'}, {'name': 'TNG50-4', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG50-4/'}, {'name': 'TNG50-4-Dark', 'num_snapshots': 100, 'url': 'http://www.tng-project.org/api/TNG50-4-Dark/'}, {'name': 'Illustris-1-Subbox0', 'num_snapshots': 3970, 'url': 'http://www.tng-project.org/api/Illustris-1-Subbox0/'}, {'name': 'Illustris-1-Subbox1', 'num_snapshots': 3969, 'url': 'http://www.tng-project.org/api/Illustris-1-Subbox1/'}, {'name': 'Illustris-1-Subbox2', 'num_snapshots': 3972, 'url': 'http://www.tng-project.org/api/Illustris-1-Subbox2/'}, {'name': 'Illustris-1-Subbox3', 'num_snapshots': 3970, 'url': 'http://www.tng-project.org/api/Illustris-1-Subbox3/'}, {'name': 'Illustris-2-Subbox0', 'num_snapshots': 2265, 'url': 'http://www.tng-project.org/api/Illustris-2-Subbox0/'}, {'name': 'Illustris-2-Subbox1', 'num_snapshots': 2265, 'url': 'http://www.tng-project.org/api/Illustris-2-Subbox1/'}, {'name': 'Illustris-2-Subbox2', 'num_snapshots': 2264, 'url': 'http://www.tng-project.org/api/Illustris-2-Subbox2/'}, {'name': 'Illustris-2-Subbox3', 'num_snapshots': 2265, 'url': 'http://www.tng-project.org/api/Illustris-2-Subbox3/'}, {'name': 'Illustris-3-Subbox0', 'num_snapshots': 1426, 'url': 'http://www.tng-project.org/api/Illustris-3-Subbox0/'}, {'name': 'Illustris-3-Subbox1', 'num_snapshots': 1426, 'url': 'http://www.tng-project.org/api/Illustris-3-Subbox1/'}, {'name': 'Illustris-3-Subbox2', 'num_snapshots': 1426, 'url': 'http://www.tng-project.org/api/Illustris-3-Subbox2/'}, {'name': 'Illustris-3-Subbox3', 'num_snapshots': 1426, 'url': 'http://www.tng-project.org/api/Illustris-3-Subbox3/'}, {'name': 'TNG100-1-Subbox0', 'num_snapshots': 7908, 'url': 'http://www.tng-project.org/api/TNG100-1-Subbox0/'}, {'name': 'TNG100-1-Subbox1', 'num_snapshots': 7908, 'url': 'http://www.tng-project.org/api/TNG100-1-Subbox1/'}, {'name': 'TNG100-2-Subbox0', 'num_snapshots': 4380, 'url': 'http://www.tng-project.org/api/TNG100-2-Subbox0/'}, {'name': 'TNG100-2-Subbox1', 'num_snapshots': 4380, 'url': 'http://www.tng-project.org/api/TNG100-2-Subbox1/'}, {'name': 'TNG100-3-Subbox0', 'num_snapshots': 2431, 'url': 'http://www.tng-project.org/api/TNG100-3-Subbox0/'}, {'name': 'TNG100-3-Subbox1', 'num_snapshots': 2431, 'url': 'http://www.tng-project.org/api/TNG100-3-Subbox1/'}, {'name': 'TNG300-3-Subbox1', 'num_snapshots': 2050, 'url': 'http://www.tng-project.org/api/TNG300-3-Subbox1/'}, {'name': 'TNG300-3-Subbox2', 'num_snapshots': 2050, 'url': 'http://www.tng-project.org/api/TNG300-3-Subbox2/'}, {'name': 'TNG300-3-Subbox0', 'num_snapshots': 2050, 'url': 'http://www.tng-project.org/api/TNG300-3-Subbox0/'}, {'name': 'TNG300-2-Subbox1', 'num_snapshots': 3045, 'url': 'http://www.tng-project.org/api/TNG300-2-Subbox1/'}, {'name': 'TNG300-2-Subbox2', 'num_snapshots': 3045, 'url': 'http://www.tng-project.org/api/TNG300-2-Subbox2/'}, {'name': 'TNG300-2-Subbox0', 'num_snapshots': 3045, 'url': 'http://www.tng-project.org/api/TNG300-2-Subbox0/'}, {'name': 'TNG300-1-Subbox1', 'num_snapshots': 2449, 'url': 'http://www.tng-project.org/api/TNG300-1-Subbox1/'}, {'name': 'TNG300-1-Subbox2', 'num_snapshots': 2449, 'url': 'http://www.tng-project.org/api/TNG300-1-Subbox2/'}, {'name': 'TNG300-1-Subbox0', 'num_snapshots': 2449, 'url': 'http://www.tng-project.org/api/TNG300-1-Subbox0/'}, {'name': 'TNG50-1-Subbox0', 'num_snapshots': 3600, 'url': 'http://www.tng-project.org/api/TNG50-1-Subbox0/'}, {'name': 'TNG50-1-Subbox2', 'num_snapshots': 3600, 'url': 'http://www.tng-project.org/api/TNG50-1-Subbox2/'}, {'name': 'TNG50-1-Subbox1', 'num_snapshots': 3600, 'url': 'http://www.tng-project.org/api/TNG50-1-Subbox1/'}, {'name': 'TNG50-2-Subbox0', 'num_snapshots': 1895, 'url': 'http://www.tng-project.org/api/TNG50-2-Subbox0/'}, {'name': 'TNG50-2-Subbox2', 'num_snapshots': 1895, 'url': 'http://www.tng-project.org/api/TNG50-2-Subbox2/'}, {'name': 'TNG50-2-Subbox1', 'num_snapshots': 1895, 'url': 'http://www.tng-project.org/api/TNG50-2-Subbox1/'}, {'name': 'TNG50-3-Subbox0', 'num_snapshots': 4006, 'url': 'http://www.tng-project.org/api/TNG50-3-Subbox0/'}, {'name': 'TNG50-3-Subbox2', 'num_snapshots': 4006, 'url': 'http://www.tng-project.org/api/TNG50-3-Subbox2/'}, {'name': 'TNG50-3-Subbox1', 'num_snapshots': 4006, 'url': 'http://www.tng-project.org/api/TNG50-3-Subbox1/'}, {'name': 'TNG50-4-Subbox0', 'num_snapshots': 2333, 'url': 'http://www.tng-project.org/api/TNG50-4-Subbox0/'}, {'name': 'TNG50-4-Subbox2', 'num_snapshots': 2333, 'url': 'http://www.tng-project.org/api/TNG50-4-Subbox2/'}, {'name': 'TNG50-4-Subbox1', 'num_snapshots': 2333, 'url': 'http://www.tng-project.org/api/TNG50-4-Subbox1/'}]}\n"
     ]
    }
   ],
   "source": [
    "r=iapi.get(baseUrl)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2277c129",
   "metadata": {},
   "source": [
    "Now, let's investigate the properties of the simulation that you have selected.\n",
    "\n",
    "To get the URL of the simulation that you are using, append the variable sim to the variable baseUrl that we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f49c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.tng-project.org/api/TNG100-1\n"
     ]
    }
   ],
   "source": [
    "#check the properties of the simulation you have selected\n",
    "simUrl = baseUrl+sim\n",
    "print(simUrl) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde5cd6",
   "metadata": {},
   "source": [
    "Feel free to follow that URL to view it in your browser (make sure that you are logged in first!)\n",
    "\n",
    "Next, we can retrieve and print the metadeta of the specific simulation using iapi.get()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9c4702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main high-resolution IllustrisTNG100 run including the full TNG physics model.\n"
     ]
    }
   ],
   "source": [
    "simdata = iapi.get(simUrl)\n",
    "print(simdata['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202d1c84",
   "metadata": {},
   "source": [
    "That is, simdata contains all of the simulation-level metadata for the simulation, saved as a Python dictionary. You can view all of the keys to the dictionary by running the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fd76c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'description', 'name_alt', 'boxsize', 'z_start', 'z_final', 'cosmology', 'omega_0', 'omega_L', 'omega_B', 'hubble', 'physics_model', 'has_cooling', 'has_starformation', 'has_winds', 'has_blackholes', 'mass_gas', 'mass_dm', 'softening_dm_comoving', 'softening_stars_comoving', 'softening_blackholes_comoving', 'softening_gas_comoving', 'softening_dm_max_phys', 'softening_stars_max_phys', 'softening_blackholes_max_phys', 'softening_gas_max_phys', 'softening_gas_factor', 'softening_gas_comoving_min', 'num_dm', 'num_tr_mc', 'num_tr_vel', 'longids', 'is_uniform', 'is_zoom', 'is_subbox', 'num_files_snapshot', 'num_files_groupcat', 'num_files_rockstar', 'num_files_lhalotree', 'num_files_sublink', 'num_files_ctrees', 'filesize_lhalotree', 'filesize_sublink', 'filesize_ctrees', 'filesize_ics', 'filesize_simulation', 'has_fof', 'has_subfind', 'has_rockstar', 'has_lhalotree', 'has_sublink', 'has_ctrees', 'permission_required', 'num_snapshots', 'url', 'parent_simulation', 'child_simulations', 'files', 'checksums', 'snapshots'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simdata.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fd8925",
   "metadata": {},
   "source": [
    "### Exercise (don't skip!): Find value of Hubble's constant used in the simulation you chose to explore\n",
    "In simulations, units often include 'little h' or Hubble's constant divided by 100.\n",
    "\n",
    "In these simulations, the value of h is stored in the simulation data as the key 'hubble'.\n",
    "\n",
    "In the following code block, determine the value of h from the simulation's metadata. (Hint: should find h=0.6774)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f965b2ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43msimdata\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhubble\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(h)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simdata' is not defined"
     ]
    }
   ],
   "source": [
    "h = simdata.get('hubble')\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eec44e",
   "metadata": {},
   "source": [
    "### Group catalogs\n",
    "\n",
    "Group catalogs contain properies of all identified halos or subhalos (galaxies) in a given snapshot. These are good for obtaining masses, positions, and other global properties. You can check out details about the available fields here: https://www.tng-project.org/data/docs/specifications/#sec2 \n",
    "\n",
    "In iapi_TNG there are two similar functions that obtain a field for all subhalos or all halos in a given simulation at a given snapshot:\n",
    "\n",
    "> getSubhaloField(field, simulation='TNG100-1', snapshot=99, fileName='tempCat', rewriteFile=1)\n",
    "\n",
    "> getHaloField(field, simulation='TNG100-1', snapshot=99, fileName='tempCat', rewriteFile=1)\n",
    "\n",
    "- field (str): name of field to be returned from the table linked above, e.g. 'SubhaloPos'\n",
    "- simulation (str): name of simulation, e.g. 'TNG100-1'\n",
    "- snapshot (int): snapshot to pull data from. For TNG, snapshot=99 is z=0, which is the default\n",
    "- fileName (str): path to the file where you want to save the data, recommended to avoid repeated API requests\n",
    "- rewriteFile (0 or 1): if 0 (recommended), will attempt to pull from an existing file (fileName) before downloading; if 1 will download and overwrite\n",
    "\n",
    "Now let's fetch the fields that we will want for our later analysis.\n",
    "\n",
    "First, the 'SubhaloFlag' indicates whether a subhalo is cosmological in origin. Generally, we only want to use data from subhalos that have flag=1.\n",
    "\n",
    "For now, we will pull the subhalo flags with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08fc967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dirc + 'catalogs'):\n",
    "    os.makedirs(dirc + 'catalogs')\n",
    "    print(f'created directory: {dirc} \"catalogs\"')\n",
    "if not os.path.exists(dirc + 'catalogs/SubhaloFlag'):\n",
    "    os.makedirs(dirc + 'catalogs/SubhaloFlag')\n",
    "    print(f'created directory: {dirc} \"/catalogs/SubhaloFlag\"')\n",
    "flag=iapi.getSubhaloField('SubhaloFlag',simulation=sim,fileName=dirc+'catalogs/SubhaloFlag',rewriteFile=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71637b78",
   "metadata": {},
   "source": [
    "Next, we can pull all of the positions of the subhalos. Note that the positions are in units of comoving Kpc/h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa5d205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=iapi.getSubhaloField('SubhaloPos',fileName=dirc + 'catalogs/SubhaloPos',rewriteFile=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ef905",
   "metadata": {},
   "source": [
    "Next, let's fetch a field that will tell us about the mass of the galaxy. 'SubhaloMassType' gives the total mass of all bound particles, separated by particle type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "232cd827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4371211, 6)\n"
     ]
    }
   ],
   "source": [
    "#let's fetch a field that will tell us about the mass of the galaxy\n",
    "#SubhaloMassType gives the total mass of all bound particles, separated by particle type\n",
    "mass=iapi.getSubhaloField('SubhaloMassType',simulation=sim,fileName=dirc+'catalogs/MassType',rewriteFile=0)\n",
    "print(mass.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba9a6b",
   "metadata": {},
   "source": [
    "Notice that there are 6 entries for each subhalo, one for each particle type:\n",
    "\n",
    "0. gas\n",
    "1. dark matter\n",
    "2. unused\n",
    "3. tracers (you can ignore these)\n",
    "4. stars/wind\n",
    "5. black holes.\n",
    "\n",
    "To pull the stellar masses, we can splice the previous with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10bb8e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[251.01631   37.85255   42.482437 ...   0.         0.         0.      ]\n"
     ]
    }
   ],
   "source": [
    "#Pull the stellar mass: \n",
    "stellar_mass=mass[:,4]\n",
    "print(stellar_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d367db",
   "metadata": {},
   "source": [
    "According to the documentation, these masses are given in units of 10^10 M_\\odot / h. To convert those to physical units we can run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e982e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "stellar_mass=stellar_mass*10**10/h\n",
    "#running into an error? did you define h above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e39a9dd",
   "metadata": {},
   "source": [
    "We will also be working with star formation rates. \n",
    "\n",
    "The subhalo catalog includes 'SubhaloSFR', which is the sum of SFRs over all gas particles bound to the subhalo (i.e., an instantaneous star formation rate).\n",
    "These are NOT directly comparable to SFRs obtained from observations since observational tracers generally detect already formed stars, not stars about to be formed\n",
    "\n",
    "If we want to get more comparable SFRs, we'll have to dig into particle data or merger trees, which we will get to later.\n",
    "\n",
    "For now, let's pull the instantaneous star formation rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "119fd1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created directory: /Users/alexpoulin/Downloads/git/TNG/TNG_workshop/TNG_workshop_data/ \"catalogs/SubhaloSFR\"\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(dirc + 'catalogs/SubhaloSFR'):\n",
    "    os.makedirs(dirc + 'catalogs/SubhaloSFR')\n",
    "    print(f'created directory: {dirc} \"catalogs/SubhaloSFR\"')\n",
    "sfr_inst = iapi.getSubhaloField('SubhaloSFR',simulation = sim,fileName=dirc+'catalogs/SubhaloSFR',rewriteFile=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169f10ab",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "There are several other fields relating to galaxy mass. Review those found at the link above and fetch at least one other field relating to mass. Later, we will test the effect of using other definitions of mass on the global star formation main sequence. Generally, you will want to use a mass that is most comparable to how mass was measured in observations you want to compare to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7cea4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pull an additional stellar mass field ###\n",
    "stellar_BHmass = mass[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ceddfca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert this mass field to physical units ###\n",
    "stellar_BHmass = stellar_BHmass*10**10/h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ddd38",
   "metadata": {},
   "source": [
    "### Exercise: Metallicities\n",
    "Interested in metallicities? Reveiw the fields availalbe in the data specifications. Make sure to scroll all the way through, there are many different metallicity fields, based on both stars and gas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d975016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created directory: /Users/alexpoulin/Downloads/git/TNG/TNG_workshop/TNG_workshop_data/ \"catalogs/SubhaloGasMetallicity\"\n"
     ]
    }
   ],
   "source": [
    "### Download metallicity fields ###\n",
    "if not os.path.exists(dirc + 'catalogs/SubhaloGasMetallicity'):\n",
    "    os.makedirs(dirc + 'catalogs/SubhaloGasMetallicity')\n",
    "    print(f'created directory: {dirc} \"catalogs/SubhaloGasMetallicity\"')\n",
    "sfr_inst = iapi.getSubhaloField('SubhaloGasMetallicity',simulation = sim,fileName=dirc+'catalogs/SubhaloGasMetallicity',rewriteFile=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6481f802",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "We need to clean our data before we can use them. This usually involves making cuts to galaxy masses, magnitudes, star formation rates, etc.\n",
    "\n",
    "First, it is useful to keep track of each subhalo's ID (i.e., subID), which is the objects index into the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a32e8568",
   "metadata": {},
   "outputs": [],
   "source": [
    "subID=np.arange(0,len(stellar_mass))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6411f59b",
   "metadata": {},
   "source": [
    "Next, let's mask out any galaxy that is not cosmological in origin and that has stellar masses <= 10^8 solar masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "131ca4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before trimming, there are  4371211  subhalos in our catalog\n",
      "After trimming, there are  123056  subhalos in our catalog\n"
     ]
    }
   ],
   "source": [
    "mask = (flag==1) & (stellar_mass>10**8)\n",
    "\n",
    "print(\"Before trimming, there are \", len(stellar_mass), ' subhalos in our catalog')\n",
    "\n",
    "IDs=subID[mask]\n",
    "s_mass=stellar_mass[mask]\n",
    "sfr_i = sfr_inst[mask]\n",
    "\n",
    "print(\"After trimming, there are \", len(s_mass), ' subhalos in our catalog')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69940795",
   "metadata": {},
   "source": [
    "Lastly, we will save these fields as a Python dictionary called galcat. We will be using this catalog throughout the rest of this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68e8bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "galcat = {\n",
    "    'subID' : IDs,\n",
    "    'pos' : pos,\n",
    "    'M_*' : s_mass,\n",
    "    'SFR_inst': sfr_i\n",
    "}\n",
    "\n",
    "#save the galaxy catalog for later use\n",
    "np.save(dirc+'galcat', galcat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1fc49c",
   "metadata": {},
   "source": [
    "## Merger Trees\n",
    "\n",
    "Tracing a subhalo through cosmic time can be complicated by the major and minor mergers that ultimately form a z=0 galaxy. The merger trees trace the most massive progenitor of a subhalos through previous snapshots. See the TNG data specifications for more information: https://www.tng-project.org/data/docs/specifications/#sec2\n",
    "\n",
    "In this workshop, we will be using the SubLink merger trees.\n",
    "\n",
    "iapi_TNG contains the function gettree(snapnum,subID), which obtains the tree for a given galaxy. The trees contain all the fields in the Halo and Subhalo group catalogs, for each snapshot. Subhalo information will always be for the progenitor of the subID at snapnum. The group/halo of a subhalo may change, so the group information in previous snapshots may not be for the group the subhalo is a member of at snapnum.\n",
    "\n",
    "getredshift(snapnum) is another useful function in iapi_TNG. This returns the redfshift of a given snapshot. \n",
    "\n",
    "For this notebook, let's work with a single subhalo at a subhalo in the top middle of our sample (where galaxy indices are very roughly ordered from largest to smalles). Specifically, let's work with the galaxy whose index into IDs is 24957 (this object has a corresponding ID of 565261)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bfa2d57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123056,)\n",
      "270118\n"
     ]
    }
   ],
   "source": [
    "print(IDs.shape)\n",
    "this_index = 24957\n",
    "sub=IDs[this_index]\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4929b0",
   "metadata": {},
   "source": [
    "Next, let's use iapi.gettree() to pull the merger tree of this subhalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ab00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/alexpoulin/Downloads/git/TNG/TNG_workshop']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'trees/sublink_mpb_270118.hdf5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m dirc\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(currentdirc) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/TNG_workshop_data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#dirc = ' '.join(currentdirc) + '/backup_data/'\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m subTreeFile \u001b[38;5;241m=\u001b[39m \u001b[43miapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgettree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m99\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m subTreeFile \u001b[38;5;241m=\u001b[39m iapi\u001b[38;5;241m.\u001b[39mgettree(\u001b[38;5;241m99\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(dirc) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(sub))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(subTreeFile)\n",
      "File \u001b[0;32m~/Downloads/git/TNG/TNG_workshop/iapi_TNG.py:56\u001b[0m, in \u001b[0;36mgettree\u001b[0;34m(snapnum, subid)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(fName\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     55\u001b[0m url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.tng-project.org/api/TNG100-1/snapshots/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39msnapnum\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/subhalos/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(subid)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/sublink/mpb.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 56\u001b[0m tree\u001b[38;5;241m=\u001b[39m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfName\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(tree)\n",
      "File \u001b[0;32m~/Downloads/git/TNG/TNG_workshop/iapi_TNG.py:37\u001b[0m, in \u001b[0;36mget\u001b[0;34m(path, params, fName)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent-disposition\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39mheaders:\n\u001b[1;32m     36\u001b[0m     filename \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent-disposition\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename=\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataFile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     38\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(r\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataFile \u001b[38;5;66;03m# return the filename string\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trees/sublink_mpb_270118.hdf5'"
     ]
    }
   ],
   "source": [
    "currentdirc=!pwd\n",
    "print(currentdirc)\n",
    "dirc= ' '.join(currentdirc) + '/TNG_workshop_data/'\n",
    "#dirc = ' '.join(currentdirc) + '/backup_data/'\n",
    "\n",
    "\n",
    "subTreeFile = iapi.gettree(99, sub)\n",
    "subTreeFile = iapi.gettree(99,' '.join(dirc) + str(sub))\n",
    "print(subTreeFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccceeb0",
   "metadata": {},
   "source": [
    "This just saved the file '/trees/sublink_mpb_565261.hdf5' into your working directory. We can open that .hdf5 file using h5py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "08653e0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not Response",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#open the hdf5 file that contains the tree\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m subTree \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubTreeFile\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/arpes/lib/python3.8/site-packages/h5py/_hl/files.py:537\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    535\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrepr\u001b[39m(name)\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASCII\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[43mfilename_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m track_order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     track_order \u001b[38;5;241m=\u001b[39m h5\u001b[38;5;241m.\u001b[39mget_config()\u001b[38;5;241m.\u001b[39mtrack_order\n",
      "File \u001b[0;32m/opt/anaconda3/envs/arpes/lib/python3.8/site-packages/h5py/_hl/compat.py:19\u001b[0m, in \u001b[0;36mfilename_encode\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilename_encode\u001b[39m(filename):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    Encode filename for use in the HDF5 library.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    filenames in h5py for more information.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not Response"
     ]
    }
   ],
   "source": [
    "#open the hdf5 file that contains the tree\n",
    "subTree = h5py.File(subTreeFile,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2819ca9f",
   "metadata": {},
   "source": [
    "We can then check the fields that we have to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45ad4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subTree.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78375634",
   "metadata": {},
   "source": [
    "Next, we will pull the snapshot numbers that correspond to each entry in each of the fields for this tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf44f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull the snapshot numbers that correspond to each entry in each of the fields for this tree\n",
    "snaps = subTree['SnapNum'][:]\n",
    "print(snaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62735ee",
   "metadata": {},
   "source": [
    "Notice how the first entry corresponds to z=0! The latest entries are first, while the earliest entries are last\n",
    "\n",
    "Some subhalos have shorter merger trees than others. This particular merger tree indicates that the pregenitor of our test subhalo formed during snapshot 5. \n",
    "\n",
    "We can determine what redshift this corresponds to using iapi.getredshift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50afb41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What redshift does the earliest snapshot correspond to?\n",
    "formation_redshift = iapi.getredshift(snaps[-1])\n",
    "\n",
    "print(\"The progenitor of our test subhalo formed during redshift z = \", formation_redshift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8299deed",
   "metadata": {},
   "source": [
    "We can also do this generally for all snapshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31bc400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct an array of redshifts corresponding to snaps\n",
    "z = iapi.getredshift(snaps)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d31f6",
   "metadata": {},
   "source": [
    "### Exercise: Construct a plot of star formation rate versus redshift for this subhalo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ea7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot SFR versus redshift for this subhalo ###\n",
    "#hint: pull the SubhaloSFR field from the merger tree first\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583965f1",
   "metadata": {},
   "source": [
    "### Extension: Plot other properties versus redshift for this subhalo\n",
    "What other properties would be interested to explore as a function of redshift?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a74ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extension ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d69cc8c",
   "metadata": {},
   "source": [
    "### Particle Data\n",
    "Now, we can download some particle data that will allow us to compute luminosity-weighted ages and time-averaged star formation rates for a galaxy. Full snapshots contain way more data than we need, so we can instead pull the parameters we want from 'cutouts' - files that contain data for all particles bound to a subhalo.\n",
    "\n",
    "First, define the particle type that we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4bf4bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parttype='stars'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e32db9c",
   "metadata": {},
   "source": [
    "as well as the particle fields that we want to pull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66d3f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_fields = 'Coordinates,Masses,GFM_Metallicity,GFM_StellarFormationTime,GFM_InitialMass,GFM_StellarPhotometrics'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3bd45c",
   "metadata": {},
   "source": [
    "Note that for time-averaged SFR calculations, the initial mass of a star should be used.\n",
    "\n",
    "Lastly, use iapi.getSubcutout to pull the particle data for each of these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f2d8b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.tng-project.org/api/TNG100-1/snapshots/99/subhalos/270118/\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://data-eu.tng-project.org/cutout/subhalo/L75n1820TNG/99/270118/0.0.0.0.924.0/?token=2fee246ea762d9d71186",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cut_file \u001b[38;5;241m=\u001b[39m \u001b[43miapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetSubcutout\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mparttype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mparticle_fields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                             \u001b[49m\u001b[43msim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                             \u001b[49m\u001b[43msnapnum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m99\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mfName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirc\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcutouts/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mparttype\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(cut_file)\n",
      "File \u001b[0;32m~/Downloads/git/TNG/TNG_workshop/iapi_TNG.py:275\u001b[0m, in \u001b[0;36mgetSubcutout\u001b[0;34m(subID, parttype, params, sim, snapnum, fName)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28mprint\u001b[39m(sub_url)\n\u001b[1;32m    272\u001b[0m cutouturl\u001b[38;5;241m=\u001b[39msub[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcutouts\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubhalo\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 275\u001b[0m cutout \u001b[38;5;241m=\u001b[39m \u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcutouturl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpart_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfName\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(cutout)\n",
      "File \u001b[0;32m~/Downloads/git/TNG/TNG_workshop/iapi_TNG.py:28\u001b[0m, in \u001b[0;36mget\u001b[0;34m(path, params, fName)\u001b[0m\n\u001b[1;32m     25\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(path, params\u001b[38;5;241m=\u001b[39mparams, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# raise exception if response code is not HTTP SUCCESS (200)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39mjson() \u001b[38;5;66;03m# parse json responses automatically\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/arpes/lib/python3.8/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://data-eu.tng-project.org/cutout/subhalo/L75n1820TNG/99/270118/0.0.0.0.924.0/?token=2fee246ea762d9d71186"
     ]
    }
   ],
   "source": [
    "cut_file = iapi.getSubcutout(sub, \\\n",
    "                             parttype, \\\n",
    "                             particle_fields, \\\n",
    "                             sim=sim, \\\n",
    "                             snapnum=99, \\\n",
    "                             fName=dirc+'cutouts/'+parttype+'_'+str(sub))\n",
    "print(cut_file)\n",
    "\n",
    "#running into issues? follow the sub_url that getSubcutout prints to check if a cutout exists for this subhalo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768a2736",
   "metadata": {},
   "source": [
    "This cutout file was saved to the file /cutouts/stars_565261.hdf5 in your work directory. Feel free to open this catalog on your own and explore the particle data yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a66635",
   "metadata": {},
   "source": [
    "### Supplementary Data Catalogs\n",
    "Rather than instantaneous star formation rates from gas particles, a more observationally-comparable measure is time-averaged star formation rates. Later in this workshop we will cover how to obtain these yourself, but for now we can make use of a supplementary catalog: https://www.tng-project.org/data/docs/specifications/#sec5b\n",
    "\n",
    "First, we can download the catalog for the simulation of our choice, but note that some catalogs are only available for certain simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c183d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a large file, it may take awhile to download\n",
    "SFRf=dirc+'SubhaloSFR_ta'\n",
    "\n",
    "#If statement checks to see if the file already exists\n",
    "#it's here to make sure you do not download\n",
    "#this large file again by accident!\n",
    "if os.path.exists(SFRf): \n",
    "    sfr_cat=SFRf+'.hdf5'\n",
    "else: \n",
    "    sfr_cat = iapi.get('https://www.tng-project.org/api/'+sim+'/files/star_formation_rates.hdf5', fName=SFRf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b96221",
   "metadata": {},
   "source": [
    "Then, we can open the supplementary catalog that corresponds to the snapshot of interest with h5py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c8459af",
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_catalog = h5py.File(sfr_cat,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0fa0bc",
   "metadata": {},
   "source": [
    "Looking at its keys, we see it has an entry for multiple snapshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4dead51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['Header', 'Snapshot_1', 'Snapshot_10', 'Snapshot_11', 'Snapshot_12', 'Snapshot_13', 'Snapshot_14', 'Snapshot_15', 'Snapshot_16', 'Snapshot_17', 'Snapshot_18', 'Snapshot_19', 'Snapshot_2', 'Snapshot_20', 'Snapshot_21', 'Snapshot_22', 'Snapshot_23', 'Snapshot_24', 'Snapshot_25', 'Snapshot_26', 'Snapshot_27', 'Snapshot_28', 'Snapshot_29', 'Snapshot_3', 'Snapshot_30', 'Snapshot_31', 'Snapshot_32', 'Snapshot_33', 'Snapshot_34', 'Snapshot_35', 'Snapshot_36', 'Snapshot_37', 'Snapshot_38', 'Snapshot_39', 'Snapshot_4', 'Snapshot_40', 'Snapshot_41', 'Snapshot_42', 'Snapshot_43', 'Snapshot_44', 'Snapshot_45', 'Snapshot_46', 'Snapshot_47', 'Snapshot_48', 'Snapshot_49', 'Snapshot_5', 'Snapshot_50', 'Snapshot_51', 'Snapshot_52', 'Snapshot_53', 'Snapshot_54', 'Snapshot_55', 'Snapshot_56', 'Snapshot_57', 'Snapshot_58', 'Snapshot_59', 'Snapshot_6', 'Snapshot_60', 'Snapshot_61', 'Snapshot_62', 'Snapshot_63', 'Snapshot_64', 'Snapshot_65', 'Snapshot_66', 'Snapshot_67', 'Snapshot_68', 'Snapshot_69', 'Snapshot_7', 'Snapshot_70', 'Snapshot_71', 'Snapshot_72', 'Snapshot_73', 'Snapshot_74', 'Snapshot_75', 'Snapshot_76', 'Snapshot_77', 'Snapshot_78', 'Snapshot_79', 'Snapshot_8', 'Snapshot_80', 'Snapshot_81', 'Snapshot_82', 'Snapshot_83', 'Snapshot_84', 'Snapshot_85', 'Snapshot_86', 'Snapshot_87', 'Snapshot_88', 'Snapshot_89', 'Snapshot_9', 'Snapshot_90', 'Snapshot_91', 'Snapshot_92', 'Snapshot_93', 'Snapshot_94', 'Snapshot_95', 'Snapshot_96', 'Snapshot_97', 'Snapshot_98', 'Snapshot_99']>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supp_catalog.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e19288",
   "metadata": {},
   "source": [
    "Let's load the dictionary that corresponds to snapshot 99 and look at its keys.\n",
    "\n",
    "Notice that there are several options. There are SFRs that are calculated within certain apertures and SFRs calculated over different timescales. When comparing simulations to observations, it's important to use a timescale comparable to the observational tracer (e.g. Halpha roughly traces 10Myrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "43d101e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['SFR_MsunPerYrs_in_InRad_1000Myrs', 'SFR_MsunPerYrs_in_InRad_100Myrs', 'SFR_MsunPerYrs_in_InRad_10Myrs', 'SFR_MsunPerYrs_in_InRad_200Myrs', 'SFR_MsunPerYrs_in_InRad_50Myrs', 'SFR_MsunPerYrs_in_all_1000Myrs', 'SFR_MsunPerYrs_in_all_100Myrs', 'SFR_MsunPerYrs_in_all_10Myrs', 'SFR_MsunPerYrs_in_all_200Myrs', 'SFR_MsunPerYrs_in_all_50Myrs', 'SFR_MsunPerYrs_in_r30pkpc_1000Myrs', 'SFR_MsunPerYrs_in_r30pkpc_100Myrs', 'SFR_MsunPerYrs_in_r30pkpc_10Myrs', 'SFR_MsunPerYrs_in_r30pkpc_200Myrs', 'SFR_MsunPerYrs_in_r30pkpc_50Myrs', 'SFR_MsunPerYrs_in_r5pkpc_1000Myrs', 'SFR_MsunPerYrs_in_r5pkpc_100Myrs', 'SFR_MsunPerYrs_in_r5pkpc_10Myrs', 'SFR_MsunPerYrs_in_r5pkpc_200Myrs', 'SFR_MsunPerYrs_in_r5pkpc_50Myrs', 'SubfindID']>\n"
     ]
    }
   ],
   "source": [
    "supp_catalog_snap99 = supp_catalog['Snapshot_99']\n",
    "print(supp_catalog_snap99.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bcd71a",
   "metadata": {},
   "source": [
    "Let's pull the fields 'SubfindID' and 'SFR_MsunPerYrs_in_all_10Myrs' which pull their subfindID and star formation rate in the past 10 Myrs, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e1d7e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFR_subID = supp_catalog_snap99['SubfindID'][:]\n",
    "SFR_all_10 = supp_catalog_snap99['SFR_MsunPerYrs_in_all_10Myrs'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a905e5d0",
   "metadata": {},
   "source": [
    "Recall that we had previously trimmed the galaxy catalog that we were using. If we want to append these time-averaged star formation rates to that catalog, then we will need to match the subIDs between the two catalogs.\n",
    "\n",
    "First, make an empty array that is the same shape as galcat. We will populate this array with time-averaged star formation rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b7b6ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFR_10=np.empty(len(IDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e82788",
   "metadata": {},
   "source": [
    "Next, let's loop over every entry in galcat. We will then find the entry in SFR_subID (from the supplementary catalog) that has the same subID as the current galcat entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e455b50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.47663982  0.86949015 17.46876928 ...  0.          0.\n",
      "  0.        ]\n",
      "(123056,)\n"
     ]
    }
   ],
   "source": [
    "#For each entry in galcat:\n",
    "for i in range(0,len(IDs)):\n",
    "    \n",
    "    #we only want to match our\n",
    "    #current entry in galcat with its\n",
    "    #corresponding entry in the \n",
    "    #supplementary catalog.\n",
    "    mask = SFR_subID==IDs[i]\n",
    "    \n",
    "    #Try to assign the time-averaged SFR \n",
    "    #not all galaxies in our sample may \n",
    "    #have SFRs computed in this catalog\n",
    "    try: \n",
    "        SFR_10[i]=SFR_all_10[mask]\n",
    "    except: \n",
    "        SFR_10[i]=np.nan\n",
    "        \n",
    "print(SFR_10)\n",
    "print(SFR_10.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfd111d",
   "metadata": {},
   "source": [
    "Lastly, let's update our galcat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92d1ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "galcat['SFR_all_10']=SFR_10\n",
    "np.save(dirc+'galcat', galcat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9845bbe",
   "metadata": {},
   "source": [
    "### Extension: Edit the code above to use a different aperature, or save additional timescales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e8ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extension ###\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arpes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
